# Tutorial 2: npy
# Feeding dataset as a form of npy files.
# Note that it takes longer time since `acceptable_drop_percent_point` is tighter than other tutorial(accepts within 5% of drop)
TASK: classification
COMPRESSION_ALIAS: tutorial2_npy_yaml
COMPRESSION_CONSTRAINTS:
  objective: accuracy
  acceptable_drop_percent_point: 5.0
INPUT:
  type: pb # h5
  path: https://netspresso-test-bucket1.s3.us-east-2.amazonaws.com/datasets/CIFAR10-images.zip/models/vgg_model.zip
  image_height_width: [32, 32]
  test_accuracy_percent: 82.0
OUTPUT:
  model_type: tflite  # (future release) tftrt
  dtype: float16  # float32, float16, int8, int8_full
  test_device: pc # (future release) raspberrypi, jetson_nano
DATASET:
  type: npy
  path:
    train_y: https://netspresso-test-bucket1.s3.us-east-2.amazonaws.com/datasets/npy/train_y.npy
    train_x: https://netspresso-test-bucket1.s3.us-east-2.amazonaws.com/datasets/npy/train_x.npy
    test_x: https://netspresso-test-bucket1.s3.us-east-2.amazonaws.com/datasets/npy/test_x.npy
    test_y: https://netspresso-test-bucket1.s3.us-east-2.amazonaws.com/datasets/npy/test_y.npy
  dataloader_config:
    preprocessing:
      rescale_value: 255
      mean: [0.0, 0.0, 0.0]
      std: [1.0, 1.0, 1.0]
    default_batch_size: 16
STORAGE:
  type: s3
  s3_bucket_name: "nota-netspresso-bucket"
  region_name: "us-east-2"
  destination_path: "/0405-TEST" # specify folder name in the destination storage
  
